<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Dendro: par Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="dendro.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Dendro
   &#160;<span id="projectnumber">5.01</span>
   </div>
   <div id="projectbrief">Dendro in Greek language means tree. The Dendro library is a large scale (262K cores on ORNL&#39;s Titan) distributed memory adaptive octree framework. The main goal of Dendro is to perform large scale multiphysics simulations efficeiently in mordern supercomputers. Dendro consists of efficient parallel data structures and algorithms to perform variational ( finite element) methods and finite difference mthods on 2:1 balanced arbitary adaptive octrees which enables the users to perform simulations raning from black holes (binary black hole mergers) to blood flow in human body, where applications ranging from relativity, astrophysics to biomedical engineering.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">par Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Collection of Generic Parallel Functions: Sorting, Partitioning, Searching,...  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype.html">Mpi_datatype</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">An abstract class used for communicating messages using user-defined datatypes. The user must implement the static member function "value()" that returns the MPI_Datatype corresponding to this user-defined datatype.  <a href="classpar_1_1Mpi__datatype.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01__T_3_01double_01_4_01_4.html">Mpi_datatype&lt; _T&lt; double &gt; &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01__T_3_01float_01_4_01_4.html">Mpi_datatype&lt; _T&lt; float &gt; &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01bool_01_4.html">Mpi_datatype&lt; bool &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A template specialization of the abstract class <a class="el" href="classpar_1_1Mpi__datatype.html" title="An abstract class used for communicating messages using user-defined datatypes. The user must impleme...">Mpi_datatype</a>. This can be used for communicating messages of type "bool".  <a href="classpar_1_1Mpi__datatype_3_01bool_01_4.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01Node__Type_01_4.html">Mpi_datatype&lt; Node_Type &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A template specialization of the abstract class "Mpi_datatype" for communicating messages of type "ot::TreeNode".  <a href="classpar_1_1Mpi__datatype_3_01Node__Type_01_4.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01ot_1_1Node_01_4.html">Mpi_datatype&lt; ot::Node &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A template specialization of the abstract class "Mpi_datatype" for communicating messages of type "ot::Node".  <a href="classpar_1_1Mpi__datatype_3_01ot_1_1Node_01_4.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01ot_1_1TreeNode_01_4.html">Mpi_datatype&lt; ot::TreeNode &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A template specialization of the abstract class "Mpi_datatype" for communicating messages of type "ot::TreeNode".  <a href="classpar_1_1Mpi__datatype_3_01ot_1_1TreeNode_01_4.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01Point_01_4.html">Mpi_datatype&lt; Point &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpar_1_1Mpi__datatype_3_01std_1_1complex_3_01T_01_4_01_4.html">Mpi_datatype&lt; std::complex&lt; T &gt; &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aac5cf582d858aebfc8664def624575de"><td class="memTemplParams" colspan="2"><a id="aac5cf582d858aebfc8664def624575de"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:aac5cf582d858aebfc8664def624575de"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mpi_Isend</b> (T *buf, int count, int dest, int tag, MPI_Comm comm, MPI_Request *request)</td></tr>
<tr class="separator:aac5cf582d858aebfc8664def624575de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac77543064a0e4b331e3974e591938d6f"><td class="memTemplParams" colspan="2"><a id="ac77543064a0e4b331e3974e591938d6f"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ac77543064a0e4b331e3974e591938d6f"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mpi_Issend</b> (T *buf, int count, int dest, int tag, MPI_Comm comm, MPI_Request *request)</td></tr>
<tr class="separator:ac77543064a0e4b331e3974e591938d6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27df4c5d5f15c007e2cf7a6cad6a9c37"><td class="memTemplParams" colspan="2"><a id="a27df4c5d5f15c007e2cf7a6cad6a9c37"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a27df4c5d5f15c007e2cf7a6cad6a9c37"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mpi_Recv</b> (T *buf, int count, int source, int tag, MPI_Comm comm, MPI_Status *status)</td></tr>
<tr class="separator:a27df4c5d5f15c007e2cf7a6cad6a9c37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5323d9cac38e61044e1cca337400e683"><td class="memTemplParams" colspan="2"><a id="a5323d9cac38e61044e1cca337400e683"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a5323d9cac38e61044e1cca337400e683"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mpi_Irecv</b> (T *buf, int count, int source, int tag, MPI_Comm comm, MPI_Request *request)</td></tr>
<tr class="separator:a5323d9cac38e61044e1cca337400e683"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fc7524beb46bb8e6842d28cb2237f7a"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a5fc7524beb46bb8e6842d28cb2237f7a"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a5fc7524beb46bb8e6842d28cb2237f7a">Mpi_Gather</a> (T *sendBuffer, T *recvBuffer, int count, int root, MPI_Comm comm)</td></tr>
<tr class="separator:a5fc7524beb46bb8e6842d28cb2237f7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ff1d6aacdfaffa12428a4dd9c4fbff7"><td class="memTemplParams" colspan="2">template&lt;typename T , typename S &gt; </td></tr>
<tr class="memitem:a6ff1d6aacdfaffa12428a4dd9c4fbff7"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a6ff1d6aacdfaffa12428a4dd9c4fbff7">Mpi_Sendrecv</a> (T *sendBuf, int sendCount, int dest, int sendTag, S *recvBuf, int recvCount, int source, int recvTag, MPI_Comm comm, MPI_Status *status)</td></tr>
<tr class="separator:a6ff1d6aacdfaffa12428a4dd9c4fbff7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac07e7526826fd6076368389596162ce5"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ac07e7526826fd6076368389596162ce5"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#ac07e7526826fd6076368389596162ce5">Mpi_Bcast</a> (T *buffer, int count, int root, MPI_Comm comm)</td></tr>
<tr class="separator:ac07e7526826fd6076368389596162ce5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90f6dce40a5aa509db9d781f9346c39b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a90f6dce40a5aa509db9d781f9346c39b"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a90f6dce40a5aa509db9d781f9346c39b">Mpi_Scan</a> (T *sendbuf, T *recvbuf, int count, MPI_Op op, MPI_Comm comm)</td></tr>
<tr class="separator:a90f6dce40a5aa509db9d781f9346c39b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abac1e1f86f92235e4d34e55e5b0f29bf"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:abac1e1f86f92235e4d34e55e5b0f29bf"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#abac1e1f86f92235e4d34e55e5b0f29bf">Mpi_Reduce</a> (T *sendbuf, T *recvbuf, int count, MPI_Op op, int root, MPI_Comm comm)</td></tr>
<tr class="separator:abac1e1f86f92235e4d34e55e5b0f29bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae7ac6eb9da39eedf2dfacc18ecdea3c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:aae7ac6eb9da39eedf2dfacc18ecdea3c"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#aae7ac6eb9da39eedf2dfacc18ecdea3c">Mpi_Allreduce</a> (T *sendbuf, T *recvbuf, int count, MPI_Op op, MPI_Comm comm)</td></tr>
<tr class="separator:aae7ac6eb9da39eedf2dfacc18ecdea3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aded1f906160954431de06731e3309040"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:aded1f906160954431de06731e3309040"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#aded1f906160954431de06731e3309040">Mpi_Alltoall</a> (T *sendbuf, T *recvbuf, int count, MPI_Comm comm)</td></tr>
<tr class="separator:aded1f906160954431de06731e3309040"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9fbdf2b26107e74f8fae649f19fdfa69"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a9fbdf2b26107e74f8fae649f19fdfa69"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a9fbdf2b26107e74f8fae649f19fdfa69">Mpi_Allgatherv</a> (T *sendbuf, int sendcount, T *recvbuf, int *recvcounts, int *displs, MPI_Comm comm)</td></tr>
<tr class="separator:a9fbdf2b26107e74f8fae649f19fdfa69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9f0cb32ab06ecf591bbf32dce0bae02"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae9f0cb32ab06ecf591bbf32dce0bae02"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#ae9f0cb32ab06ecf591bbf32dce0bae02">Mpi_Allgather</a> (T *sendbuf, T *recvbuf, int count, MPI_Comm comm)</td></tr>
<tr class="separator:ae9f0cb32ab06ecf591bbf32dce0bae02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12d8b82e8478b7549a4f4dc46e0a17b6"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a12d8b82e8478b7549a4f4dc46e0a17b6"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a12d8b82e8478b7549a4f4dc46e0a17b6">Mpi_Alltoallv_sparse</a> (T *sendbuf, int *sendcnts, int *sdispls, T *recvbuf, int *recvcnts, int *rdispls, MPI_Comm comm)</td></tr>
<tr class="separator:a12d8b82e8478b7549a4f4dc46e0a17b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad84676b859c25d36e42058b15a111e71"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ad84676b859c25d36e42058b15a111e71"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#ad84676b859c25d36e42058b15a111e71">Mpi_Alltoallv_dense</a> (T *sendbuf, int *sendcnts, int *sdispls, T *recvbuf, int *recvcnts, int *rdispls, MPI_Comm comm)</td></tr>
<tr class="separator:ad84676b859c25d36e42058b15a111e71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf67d0dca36db24cc60ac0394b6dd165"><td class="memTemplParams" colspan="2"><a id="acf67d0dca36db24cc60ac0394b6dd165"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:acf67d0dca36db24cc60ac0394b6dd165"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mpi_Alltoallv_Kway</b> (T *sbuff_, int *s_cnt_, int *sdisp_, T *rbuff_, int *r_cnt_, int *rdisp_, MPI_Comm c)</td></tr>
<tr class="separator:acf67d0dca36db24cc60ac0394b6dd165"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace4f6438a0037ad6ef1ba97bde0eb24b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ace4f6438a0037ad6ef1ba97bde0eb24b"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#ace4f6438a0037ad6ef1ba97bde0eb24b">scatterValues</a> (std::vector&lt; T &gt; &amp;in, std::vector&lt; T &gt; &amp;out, DendroIntL outSz, MPI_Comm comm)</td></tr>
<tr class="memdesc:ace4f6438a0037ad6ef1ba97bde0eb24b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Re-distributes a STL vector, preserving the relative ordering of the elements.  <a href="#ace4f6438a0037ad6ef1ba97bde0eb24b">More...</a><br /></td></tr>
<tr class="separator:ace4f6438a0037ad6ef1ba97bde0eb24b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9131e559b4020008f287cd0674c8904b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a9131e559b4020008f287cd0674c8904b"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a9131e559b4020008f287cd0674c8904b">maxLowerBound</a> (const std::vector&lt; T &gt; &amp;keys, const std::vector&lt; T &gt; &amp;searchList, std::vector&lt; T &gt; &amp;results, MPI_Comm comm)</td></tr>
<tr class="memdesc:a9131e559b4020008f287cd0674c8904b"><td class="mdescLeft">&#160;</td><td class="mdescRight">A parallel search function.  <a href="#a9131e559b4020008f287cd0674c8904b">More...</a><br /></td></tr>
<tr class="separator:a9131e559b4020008f287cd0674c8904b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82194ab32047be2e560e1fbcc8e76f82"><td class="memTemplParams" colspan="2"><a id="a82194ab32047be2e560e1fbcc8e76f82"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a82194ab32047be2e560e1fbcc8e76f82"><td class="memTemplItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memTemplItemRight" valign="bottom"><b>defaultWeight</b> (const T *a)</td></tr>
<tr class="separator:a82194ab32047be2e560e1fbcc8e76f82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebcff423f403e9bb0249b9a765607257"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:aebcff423f403e9bb0249b9a765607257"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#aebcff423f403e9bb0249b9a765607257">partitionW</a> (std::vector&lt; T &gt; &amp;vec, unsigned int(*getWeight)(const T *), MPI_Comm comm)</td></tr>
<tr class="memdesc:aebcff423f403e9bb0249b9a765607257"><td class="mdescLeft">&#160;</td><td class="mdescRight">A parallel weighted partitioning function. In our implementation, we do not pose any restriction on the input or the number of processors. This function can be used with an odd number of processors as well. Some processors can pass an empty vector as input. The relative ordering of the elements is preserved.  <a href="#aebcff423f403e9bb0249b9a765607257">More...</a><br /></td></tr>
<tr class="separator:aebcff423f403e9bb0249b9a765607257"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba9704922999ccde4fbc76e7ee92d2df"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:aba9704922999ccde4fbc76e7ee92d2df"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#aba9704922999ccde4fbc76e7ee92d2df">concatenate</a> (std::vector&lt; T &gt; &amp;listA, std::vector&lt; T &gt; &amp;listB, MPI_Comm comm)</td></tr>
<tr class="memdesc:aba9704922999ccde4fbc76e7ee92d2df"><td class="mdescLeft">&#160;</td><td class="mdescRight">A parallel concatenation function. listB is appended (globally) to listA and the result is stored in listA. An useful application of this function is when listA and listB are individually sorted (globally) and the smallest element in listB is greater than the largest element in listA and we want to create a merged list that is sorted.  <a href="#aba9704922999ccde4fbc76e7ee92d2df">More...</a><br /></td></tr>
<tr class="separator:aba9704922999ccde4fbc76e7ee92d2df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c37f7aa10f230499ac93aa7637df63d"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a7c37f7aa10f230499ac93aa7637df63d"><td class="memTemplItemLeft" align="right" valign="top">int&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a7c37f7aa10f230499ac93aa7637df63d">sampleSort</a> (std::vector&lt; T &gt; &amp;in, std::vector&lt; T &gt; &amp;out, std::vector&lt; double &gt; &amp;stats, MPI_Comm comm)</td></tr>
<tr class="memdesc:a7c37f7aa10f230499ac93aa7637df63d"><td class="mdescLeft">&#160;</td><td class="mdescRight">A parallel sample sort implementation. In our implementation, we do not pose any restriction on the input or the number of processors. This function can be used with an odd number of processors as well. Some processors can pass an empty vector as input. If the total number of elements in the vector (globally) is fewer than 10*p^2, where p is the number of processors, then we will use bitonic sort instead of sample sort to sort the vector. We use a paralle bitonic sort to sort the samples in the sample sort algorithm. Hence, the complexity of the algorithm is O(n/p log n/p) + O(p log p). Here, n is the global length of the vector and p is the number of processors.  <a href="#a7c37f7aa10f230499ac93aa7637df63d">More...</a><br /></td></tr>
<tr class="separator:a7c37f7aa10f230499ac93aa7637df63d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab43c92faf7ccef4963b7b5968e534800"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacepar.html#ab43c92faf7ccef4963b7b5968e534800">splitComm2way</a> (bool iAmEmpty, MPI_Comm *new_comm, MPI_Comm orig_comm)</td></tr>
<tr class="memdesc:ab43c92faf7ccef4963b7b5968e534800"><td class="mdescLeft">&#160;</td><td class="mdescRight">Removes duplicates in parallel. If the input is not sorted, sample sort will be called within the function to sort the vector and then duplicates will be removed.  <a href="#ab43c92faf7ccef4963b7b5968e534800">More...</a><br /></td></tr>
<tr class="separator:ab43c92faf7ccef4963b7b5968e534800"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a333660b86811a5b312e9cc2d6e2991a3"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacepar.html#a333660b86811a5b312e9cc2d6e2991a3">splitComm2way</a> (const bool *isEmptyList, MPI_Comm *new_comm, MPI_Comm orig_comm)</td></tr>
<tr class="memdesc:a333660b86811a5b312e9cc2d6e2991a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Splits a communication group into two depending on the values in isEmptyList. Both the groups are sorted in the ascending order of their ranks in the old comm. All processors must call this function with the same 'isEmptyList' array.  <a href="#a333660b86811a5b312e9cc2d6e2991a3">More...</a><br /></td></tr>
<tr class="separator:a333660b86811a5b312e9cc2d6e2991a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9c30f45534c8b8a18c0918db069265c"><td class="memItemLeft" align="right" valign="top"><a id="ae9c30f45534c8b8a18c0918db069265c"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>splitCommUsingSplittingRank</b> (int splittingRank, MPI_Comm *new_comm, MPI_Comm orig_comm)</td></tr>
<tr class="separator:ae9c30f45534c8b8a18c0918db069265c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f6e633d08c91c48b3ea470e07ebdc90"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacepar.html#a7f6e633d08c91c48b3ea470e07ebdc90">splitCommBinary</a> (MPI_Comm orig_comm, MPI_Comm *new_comm)</td></tr>
<tr class="memdesc:a7f6e633d08c91c48b3ea470e07ebdc90"><td class="mdescLeft">&#160;</td><td class="mdescRight">Splits a communication group into two, the first having a power of 2 number of processors and the other having the remainder. The first group is sorted in the ascending order of their ranks in the old comm and the second group is sorted in the descending order of their ranks in the old comm.  <a href="#a7f6e633d08c91c48b3ea470e07ebdc90">More...</a><br /></td></tr>
<tr class="separator:a7f6e633d08c91c48b3ea470e07ebdc90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6208b60f6b6b60614b2c8e883d393d0"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacepar.html#ae6208b60f6b6b60614b2c8e883d393d0">splitCommBinaryNoFlip</a> (MPI_Comm orig_comm, MPI_Comm *new_comm)</td></tr>
<tr class="memdesc:ae6208b60f6b6b60614b2c8e883d393d0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Splits a communication group into two, the first having a power of 2 number of processors and the other having the remainder. Both the groups are sorted in the ascending order of their ranks in the old comm.  <a href="#ae6208b60f6b6b60614b2c8e883d393d0">More...</a><br /></td></tr>
<tr class="separator:ae6208b60f6b6b60614b2c8e883d393d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3b8391c3ddda3ceea327c8f4df32b0e"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae3b8391c3ddda3ceea327c8f4df32b0e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#ae3b8391c3ddda3ceea327c8f4df32b0e">MergeLists</a> (std::vector&lt; T &gt; &amp;listA, std::vector&lt; T &gt; &amp;listB, int KEEP_WHAT)</td></tr>
<tr class="memdesc:ae3b8391c3ddda3ceea327c8f4df32b0e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Merges lists A, and B, retaining either the low or the High in list A.  <a href="#ae3b8391c3ddda3ceea327c8f4df32b0e">More...</a><br /></td></tr>
<tr class="separator:ae3b8391c3ddda3ceea327c8f4df32b0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abad721e799fda8d9b03f005c82dfd907"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:abad721e799fda8d9b03f005c82dfd907"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#abad721e799fda8d9b03f005c82dfd907">MergeSplit</a> (std::vector&lt; T &gt; &amp;local_list, int which_keys, int partner, MPI_Comm comm)</td></tr>
<tr class="memdesc:abad721e799fda8d9b03f005c82dfd907"><td class="mdescLeft">&#160;</td><td class="mdescRight">The main operation in the parallel bitonic sort algorithm. This implements the compare-split operation.  <a href="#abad721e799fda8d9b03f005c82dfd907">More...</a><br /></td></tr>
<tr class="separator:abad721e799fda8d9b03f005c82dfd907"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88e164ad279018147554138bbb8716c6"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a88e164ad279018147554138bbb8716c6"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a88e164ad279018147554138bbb8716c6">Par_bitonic_sort_incr</a> (std::vector&lt; T &gt; &amp;local_list, int proc_set_size, MPI_Comm comm)</td></tr>
<tr class="separator:a88e164ad279018147554138bbb8716c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5681739fc044d4774f199186027bc82"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:aa5681739fc044d4774f199186027bc82"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#aa5681739fc044d4774f199186027bc82">Par_bitonic_sort_decr</a> (std::vector&lt; T &gt; &amp;local_list, int proc_set_size, MPI_Comm comm)</td></tr>
<tr class="separator:aa5681739fc044d4774f199186027bc82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63eb714a90c5cf391b0c37baa804644c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a63eb714a90c5cf391b0c37baa804644c"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a63eb714a90c5cf391b0c37baa804644c">Par_bitonic_merge_incr</a> (std::vector&lt; T &gt; &amp;local_list, int proc_set_size, MPI_Comm comm)</td></tr>
<tr class="separator:a63eb714a90c5cf391b0c37baa804644c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e3992a13172d29616c6d877d283178c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a0e3992a13172d29616c6d877d283178c"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a0e3992a13172d29616c6d877d283178c">bitonicSort_binary</a> (std::vector&lt; T &gt; &amp;in, MPI_Comm comm)</td></tr>
<tr class="memdesc:a0e3992a13172d29616c6d877d283178c"><td class="mdescLeft">&#160;</td><td class="mdescRight">An implementation of parallel bitonic sort that expects the number of processors to be a power of 2. However, unlike most implementations, we do not expect the length of the vector (neither locally nor globally) to be a power of 2 or even. Moreover, each processor can call this with a different number of elements. However, we do expect that 'in' atleast has 1 element on each processor.  <a href="#a0e3992a13172d29616c6d877d283178c">More...</a><br /></td></tr>
<tr class="separator:a0e3992a13172d29616c6d877d283178c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41724fba006b22060f83b15d96e81e5b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a41724fba006b22060f83b15d96e81e5b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacepar.html#a41724fba006b22060f83b15d96e81e5b">bitonicSort</a> (std::vector&lt; T &gt; &amp;in, MPI_Comm comm)</td></tr>
<tr class="memdesc:a41724fba006b22060f83b15d96e81e5b"><td class="mdescLeft">&#160;</td><td class="mdescRight">An implementation of parallel bitonic sort that does not expect the number of processors to be a power of 2. In fact, the number of processors can even be odd. Moreover, we do not even expect the length of the vector (neither locally nor globally) to be a power of 2 or even. Moreover, each processor can call this with a different number of elements. However, we do expect that 'in' atleast has 1 element on each processor. This recursively calls the function bitonicSort_binary, followed by a special parallel merge.  <a href="#a41724fba006b22060f83b15d96e81e5b">More...</a><br /></td></tr>
<tr class="separator:a41724fba006b22060f83b15d96e81e5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12c68581cdd3284eb90373283827c0ea"><td class="memTemplParams" colspan="2"><a id="a12c68581cdd3284eb90373283827c0ea"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a12c68581cdd3284eb90373283827c0ea"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><b>parallel_rank</b> (const T *in, unsigned int sz, DendroIntL *out, MPI_Comm comm)</td></tr>
<tr class="separator:a12c68581cdd3284eb90373283827c0ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Collection of Generic Parallel Functions: Sorting, Partitioning, Searching,... </p>
<dl class="section author"><dt>Author</dt><dd>Rahul Sampath </dd>
<dd>
Hari Sundar </dd></dl>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="a41724fba006b22060f83b15d96e81e5b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a41724fba006b22060f83b15d96e81e5b">&#9670;&nbsp;</a></span>bitonicSort()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::bitonicSort </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>An implementation of parallel bitonic sort that does not expect the number of processors to be a power of 2. In fact, the number of processors can even be odd. Moreover, we do not even expect the length of the vector (neither locally nor globally) to be a power of 2 or even. Moreover, each processor can call this with a different number of elements. However, we do expect that 'in' atleast has 1 element on each processor. This recursively calls the function bitonicSort_binary, followed by a special parallel merge. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>the vector to be sorted </td></tr>
  </table>
  </dd>
</dl>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="namespacepar.html#a0e3992a13172d29616c6d877d283178c" title="An implementation of parallel bitonic sort that expects the number of processors to be a power of 2...">bitonicSort_binary</a> </dd></dl>

</div>
</div>
<a id="a0e3992a13172d29616c6d877d283178c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e3992a13172d29616c6d877d283178c">&#9670;&nbsp;</a></span>bitonicSort_binary()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::bitonicSort_binary </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>An implementation of parallel bitonic sort that expects the number of processors to be a power of 2. However, unlike most implementations, we do not expect the length of the vector (neither locally nor globally) to be a power of 2 or even. Moreover, each processor can call this with a different number of elements. However, we do expect that 'in' atleast has 1 element on each processor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>the vector to be sorted </td></tr>
  </table>
  </dd>
</dl>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>

</div>
</div>
<a id="aba9704922999ccde4fbc76e7ee92d2df"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba9704922999ccde4fbc76e7ee92d2df">&#9670;&nbsp;</a></span>concatenate()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::concatenate </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>listA</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>listB</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>A parallel concatenation function. listB is appended (globally) to listA and the result is stored in listA. An useful application of this function is when listA and listB are individually sorted (globally) and the smallest element in listB is greater than the largest element in listA and we want to create a merged list that is sorted. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">listA</td><td>a distributed vector, the result is stored in listA </td></tr>
    <tr><td class="paramname">listB</td><td>another distributed vector that is appended to listA listA must not be empty on any of the calling processors. listB can be empty on some of the calling processors. listB will be cleared within the function. </td></tr>
    <tr><td class="paramname">comm</td><td>the communicator </td></tr>
  </table>
  </dd>
</dl>
<dl class="section author"><dt>Author</dt><dd>Rahul Sampath </dd></dl>

</div>
</div>
<a id="a9131e559b4020008f287cd0674c8904b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9131e559b4020008f287cd0674c8904b">&#9670;&nbsp;</a></span>maxLowerBound()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::maxLowerBound </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>keys</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>searchList</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>results</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>A parallel search function. </p>
<dl class="section author"><dt>Author</dt><dd>Rahul Sampath </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">keys</td><td>locally sorted unique list of keys </td></tr>
    <tr><td class="paramname">searchList</td><td>globally sorted unique list. No processor must call this function with an empty list. </td></tr>
    <tr><td class="paramname">results</td><td>maximum lower bound in searchList for the corresponding key </td></tr>
    <tr><td class="paramname">comm</td><td>MPI communicator</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int errorcode </dd></dl>

</div>
</div>
<a id="ae3b8391c3ddda3ceea327c8f4df32b0e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3b8391c3ddda3ceea327c8f4df32b0e">&#9670;&nbsp;</a></span>MergeLists()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::MergeLists </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>listA</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>listB</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>KEEP_WHAT</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Merges lists A, and B, retaining either the low or the High in list A. </p>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">listA</td><td>Input list, and where the output is stored. </td></tr>
    <tr><td class="paramname">listB</td><td>Second input list. </td></tr>
    <tr><td class="paramname">KEEP_WHAT</td><td>determines whether to retain the High or the low values from A and B. One of KEEP_HIGH or KEEP_LOW.</td></tr>
  </table>
  </dd>
</dl>
<p>Merging the two lists when their sizes are not the same is a bit involved. The major condition that needs to be used is that all elements that are less than max(min(A), min(B)) are retained by the KEEP_LOW processor, and similarly all elements that are larger larger than min(max(A), max(B)) are retained by the KEEP_HIGH processor.</p>
<p>The reason for this is that, on the Keep_Low side,</p>
<p>max(min(A), min(B)) &gt; min(A) &gt; max(A-)</p>
<p>and similarly on the Keep_high side,</p>
<p>min(max(A), max(B)) &lt; max(A) &lt; min(A+)</p>
<p>which guarantees that the merged lists remain bitonic. </p>

</div>
</div>
<a id="abad721e799fda8d9b03f005c82dfd907"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abad721e799fda8d9b03f005c82dfd907">&#9670;&nbsp;</a></span>MergeSplit()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::MergeSplit </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>local_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>which_keys</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>partner</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The main operation in the parallel bitonic sort algorithm. This implements the compare-split operation. </p>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">which_keys</td><td>is one of KEEP_HIGH or KEEP_LOW </td></tr>
    <tr><td class="paramname">partner</td><td>is the processor with which to Merge and Split. </td></tr>
    <tr><td class="paramname">local_list</td><td>the input vector </td></tr>
    <tr><td class="paramname">comm</td><td>the communicator </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae9f0cb32ab06ecf591bbf32dce0bae02"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9f0cb32ab06ecf591bbf32dce0bae02">&#9670;&nbsp;</a></span>Mpi_Allgather()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Allgather </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="a9fbdf2b26107e74f8fae649f19fdfa69"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9fbdf2b26107e74f8fae649f19fdfa69">&#9670;&nbsp;</a></span>Mpi_Allgatherv()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Allgatherv </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sendcount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>recvcounts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>displs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="aae7ac6eb9da39eedf2dfacc18ecdea3c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae7ac6eb9da39eedf2dfacc18ecdea3c">&#9670;&nbsp;</a></span>Mpi_Allreduce()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Allreduce </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Op&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="aded1f906160954431de06731e3309040"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aded1f906160954431de06731e3309040">&#9670;&nbsp;</a></span>Mpi_Alltoall()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Alltoall </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="ad84676b859c25d36e42058b15a111e71"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad84676b859c25d36e42058b15a111e71">&#9670;&nbsp;</a></span>Mpi_Alltoallv_dense()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Alltoallv_dense </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>sendcnts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>sdispls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>recvcnts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>rdispls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="a12d8b82e8478b7549a4f4dc46e0a17b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12d8b82e8478b7549a4f4dc46e0a17b6">&#9670;&nbsp;</a></span>Mpi_Alltoallv_sparse()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Alltoallv_sparse </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>sendcnts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>sdispls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>recvcnts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>rdispls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="ac07e7526826fd6076368389596162ce5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac07e7526826fd6076368389596162ce5">&#9670;&nbsp;</a></span>Mpi_Bcast()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Bcast </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>buffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>root</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="a5fc7524beb46bb8e6842d28cb2237f7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fc7524beb46bb8e6842d28cb2237f7a">&#9670;&nbsp;</a></span>Mpi_Gather()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Gather </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendBuffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvBuffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>root</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="abac1e1f86f92235e4d34e55e5b0f29bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abac1e1f86f92235e4d34e55e5b0f29bf">&#9670;&nbsp;</a></span>Mpi_Reduce()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Reduce </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Op&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>root</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="a90f6dce40a5aa509db9d781f9346c39b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90f6dce40a5aa509db9d781f9346c39b">&#9670;&nbsp;</a></span>Mpi_Scan()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Scan </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>recvbuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Op&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="a6ff1d6aacdfaffa12428a4dd9c4fbff7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ff1d6aacdfaffa12428a4dd9c4fbff7">&#9670;&nbsp;</a></span>Mpi_Sendrecv()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , typename S &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::Mpi_Sendrecv </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>sendBuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sendCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>dest</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sendTag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">S *&#160;</td>
          <td class="paramname"><em>recvBuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>recvCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>source</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>recvTag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Status *&#160;</td>
          <td class="paramname"><em>status</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>

</div>
</div>
<a id="a63eb714a90c5cf391b0c37baa804644c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63eb714a90c5cf391b0c37baa804644c">&#9670;&nbsp;</a></span>Par_bitonic_merge_incr()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::Par_bitonic_merge_incr </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>local_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>proc_set_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>

</div>
</div>
<a id="aa5681739fc044d4774f199186027bc82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5681739fc044d4774f199186027bc82">&#9670;&nbsp;</a></span>Par_bitonic_sort_decr()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::Par_bitonic_sort_decr </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>local_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>proc_set_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>

</div>
</div>
<a id="a88e164ad279018147554138bbb8716c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88e164ad279018147554138bbb8716c6">&#9670;&nbsp;</a></span>Par_bitonic_sort_incr()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void par::Par_bitonic_sort_incr </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>local_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>proc_set_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>

</div>
</div>
<a id="aebcff423f403e9bb0249b9a765607257"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aebcff423f403e9bb0249b9a765607257">&#9670;&nbsp;</a></span>partitionW()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::partitionW </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int(*)(const T *)&#160;</td>
          <td class="paramname"><em>getWeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>A parallel weighted partitioning function. In our implementation, we do not pose any restriction on the input or the number of processors. This function can be used with an odd number of processors as well. Some processors can pass an empty vector as input. The relative ordering of the elements is preserved. </p>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd>
<dd>
Rahul Sampath </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vec</td><td>the input vector </td></tr>
    <tr><td class="paramname">getWeight</td><td>function pointer to compute the weight of each element. If you pass NULL, then every element will get a weight equal to 1. </td></tr>
    <tr><td class="paramname">comm</td><td>the communicator </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7c37f7aa10f230499ac93aa7637df63d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c37f7aa10f230499ac93aa7637df63d">&#9670;&nbsp;</a></span>sampleSort()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::sampleSort </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>A parallel sample sort implementation. In our implementation, we do not pose any restriction on the input or the number of processors. This function can be used with an odd number of processors as well. Some processors can pass an empty vector as input. If the total number of elements in the vector (globally) is fewer than 10*p^2, where p is the number of processors, then we will use bitonic sort instead of sample sort to sort the vector. We use a paralle bitonic sort to sort the samples in the sample sort algorithm. Hence, the complexity of the algorithm is O(n/p log n/p) + O(p log p). Here, n is the global length of the vector and p is the number of processors. </p>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd>
<dd>
Rahul Sampath </dd>
<dd>
Santi Swaroop Adavani </dd>
<dd>
Shravan Veerapaneni </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>the input vector </td></tr>
    <tr><td class="paramname">out</td><td>the output vector </td></tr>
    <tr><td class="paramname">comm</td><td>the communicator </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ace4f6438a0037ad6ef1ba97bde0eb24b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace4f6438a0037ad6ef1ba97bde0eb24b">&#9670;&nbsp;</a></span>scatterValues()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">int par::scatterValues </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">DendroIntL&#160;</td>
          <td class="paramname"><em>outSz</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Re-distributes a STL vector, preserving the relative ordering of the elements. </p>
<dl class="section author"><dt>Author</dt><dd>Rahul S. Sampath </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>The input vector </td></tr>
    <tr><td class="paramname">out</td><td>The output vector. Memory for this vector will be allocated within the function. </td></tr>
    <tr><td class="paramname">outSz</td><td>The local size of the output vector on the calling processor. </td></tr>
    <tr><td class="paramname">comm</td><td>The communicator </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>error flag </dd></dl>

</div>
</div>
<a id="ab43c92faf7ccef4963b7b5968e534800"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab43c92faf7ccef4963b7b5968e534800">&#9670;&nbsp;</a></span>splitComm2way() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int par::splitComm2way </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>iAmEmpty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm *&#160;</td>
          <td class="paramname"><em>new_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>orig_comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Removes duplicates in parallel. If the input is not sorted, sample sort will be called within the function to sort the vector and then duplicates will be removed. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nodes</td><td>the input vector. </td></tr>
    <tr><td class="paramname">isSorted</td><td>pass 'true' if the vector is globally sorted. </td></tr>
    <tr><td class="paramname">comm</td><td>The communicator </td></tr>
  </table>
  </dd>
</dl>
<dl class="section author"><dt>Author</dt><dd>Rahul Sampath Splits a communication group into two, one containing processors that passed a value of 'false' for the parameter 'iAmEmpty' and the another containing processors that passed a value of 'true' for the parameter. Both the groups are sorted in the ascending order of their ranks in the old comm. </dd>
<dd>
Rahul Sampath </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">iAmEmpty</td><td>Some flag to determine which group the calling processor will be combined into. </td></tr>
    <tr><td class="paramname">orig_comm</td><td>The comm group that needs to be split. </td></tr>
    <tr><td class="paramname">new_comm</td><td>The new comm group. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a333660b86811a5b312e9cc2d6e2991a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a333660b86811a5b312e9cc2d6e2991a3">&#9670;&nbsp;</a></span>splitComm2way() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int par::splitComm2way </td>
          <td>(</td>
          <td class="paramtype">const bool *&#160;</td>
          <td class="paramname"><em>isEmptyList</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm *&#160;</td>
          <td class="paramname"><em>new_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>orig_comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Splits a communication group into two depending on the values in isEmptyList. Both the groups are sorted in the ascending order of their ranks in the old comm. All processors must call this function with the same 'isEmptyList' array. </p>
<dl class="section author"><dt>Author</dt><dd>Rahul Sampath </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">isEmptyList</td><td>flags (of length equal to the number of processors) to determine whether each processor is active or not. </td></tr>
    <tr><td class="paramname">orig_comm</td><td>The comm group that needs to be split. </td></tr>
    <tr><td class="paramname">new_comm</td><td>The new comm group. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7f6e633d08c91c48b3ea470e07ebdc90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7f6e633d08c91c48b3ea470e07ebdc90">&#9670;&nbsp;</a></span>splitCommBinary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int par::splitCommBinary </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>orig_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm *&#160;</td>
          <td class="paramname"><em>new_comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Splits a communication group into two, the first having a power of 2 number of processors and the other having the remainder. The first group is sorted in the ascending order of their ranks in the old comm and the second group is sorted in the descending order of their ranks in the old comm. </p>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">orig_comm</td><td>The comm group that needs to be split. </td></tr>
    <tr><td class="paramname">new_comm</td><td>The new comm group. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae6208b60f6b6b60614b2c8e883d393d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6208b60f6b6b60614b2c8e883d393d0">&#9670;&nbsp;</a></span>splitCommBinaryNoFlip()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int par::splitCommBinaryNoFlip </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>orig_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MPI_Comm *&#160;</td>
          <td class="paramname"><em>new_comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Splits a communication group into two, the first having a power of 2 number of processors and the other having the remainder. Both the groups are sorted in the ascending order of their ranks in the old comm. </p>
<dl class="section author"><dt>Author</dt><dd>Hari Sundar </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">orig_comm</td><td>The comm group that needs to be split. </td></tr>
    <tr><td class="paramname">new_comm</td><td>The new comm group. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
